{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "158b1d13",
   "metadata": {},
   "source": [
    "# Genie: 蛋白质从头设计演示 (De Novo Protein Design Demo)\n",
    "\n",
    "本笔记演示了 Genie 模型的完整流程：从训练到采样再到评估。\n",
    "This notebook demonstrates the complete workflow of the Genie model: from training to sampling and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d4a83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import shutil\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Add current directory to path\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from genie.config import Config\n",
    "from genie.utils.model_io import load_model\n",
    "\n",
    "# Check GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa74f7a8",
   "metadata": {},
   "source": [
    "## 2. 训练 (Training)\n",
    "\n",
    "如果你想从头训练一个新模型，可以使用 `train.py`。\n",
    "If you want to train a new model from scratch, you can use `train.py`.\n",
    "\n",
    "训练过程通常需要你自行在终端运行，因为它涉及到分布式训练（多GPU）和长时间运行。\n",
    "Training is typically run in a terminal as it involves distributed training (multi-GPU) and long runtimes.\n",
    "\n",
    "以下是启动训练的命令示例：\n",
    "Here is an example command to start training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cd789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"To train a new model (Command to run in terminal):\")\n",
    "print(\"python genie/train.py --config example_configuration --gpus 0,1\")\n",
    "\n",
    "# 配置文件定义了超参数。详情请查看 genie/config.py\n",
    "# Configuration files define hyperparameters. See genie/config.py for details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3654824b",
   "metadata": {},
   "source": [
    "## 3. 准备预训练权重 (Prepare Pre-trained Weights)\n",
    "\n",
    "如果你不进行训练，而是使用提供的预训练权重进行采样，请继续此步骤。\n",
    "If you are skipping training and using provided pre-trained weights for sampling, proceed with this step.\n",
    "\n",
    "提供的权重文件结构是扁平的。采样脚本需要特定的目录层级 (`runs/<model_name>/version_<X>/checkpoints/`)。我们将创建一个临时的 `runs` 目录并正确链接权重。\n",
    "The provided weights are in a flat structure. The sampling script expects a specific directory hierarchy (`runs/<model_name>/version_<X>/checkpoints/`). We will create a temporary `runs` directory and link the weights correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80adcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_weights(source_path, model_name, target_root='runs', version=0):\n",
    "    \"\"\"\n",
    "    Restructures weights from source_path to target_root compatible with Genie's loader.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Target paths\n",
    "    run_dir = os.path.join(target_root, model_name)\n",
    "    version_dir = os.path.join(run_dir, f'version_{version}')\n",
    "    ckpt_dir = os.path.join(version_dir, 'checkpoints')\n",
    "    \n",
    "    # Create directories\n",
    "    os.makedirs(ckpt_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Copy/Link Configuration\n",
    "    src_config = os.path.join(source_path, 'configuration')\n",
    "    dst_config = os.path.join(run_dir, 'configuration')\n",
    "    if os.path.exists(src_config) and not os.path.exists(dst_config):\n",
    "        shutil.copy(src_config, dst_config)\n",
    "        print(f\"Copied configuration to {dst_config}\")\n",
    "        \n",
    "    # 2. Link Checkpoint\n",
    "    # Find .ckpt file in source\n",
    "    ckpts = glob.glob(os.path.join(source_path, '*.ckpt'))\n",
    "    if not ckpts:\n",
    "        raise FileNotFoundError(f\"No .ckpt files found in {source_path}\")\n",
    "    \n",
    "    src_ckpt = ckpts[0] # Take the first one found\n",
    "    ckpt_name = os.path.basename(src_ckpt)\n",
    "    dst_ckpt = os.path.join(ckpt_dir, ckpt_name)\n",
    "    \n",
    "    if not os.path.exists(dst_ckpt):\n",
    "        # Use symlink if possible, else copy\n",
    "        try:\n",
    "            os.symlink(os.path.abspath(src_ckpt), dst_ckpt)\n",
    "            print(f\"Symlinked checkpoint to {dst_ckpt}\")\n",
    "        except OSError:\n",
    "            shutil.copy(src_ckpt, dst_ckpt)\n",
    "            print(f\"Copied checkpoint to {dst_ckpt}\")\n",
    "\n",
    "# Define model to use\n",
    "MODEL_NAME = 'scope_l_128'\n",
    "WEIGHTS_PATH = os.path.join('weights', MODEL_NAME)\n",
    "\n",
    "# Set up the folder structure\n",
    "setup_weights(WEIGHTS_PATH, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819d6375",
   "metadata": {},
   "source": [
    "## 4. 采样 (Sampling)\n",
    "\n",
    "现在我们加载模型并生成一些蛋白质骨架结构。\n",
    "作为示例，我们将生成长度为 64 的蛋白质。\n",
    "\n",
    "Now we load the model and generate some protein backbone structures.\n",
    "We will generate proteins of length 64 as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c1108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for sampling\n",
    "MODEL_VERSION = 0 # As set up above\n",
    "ROOT_DIR = 'runs'\n",
    "BATCH_SIZE = 1 # Number of samples per batch\n",
    "NOISE_SCALE = 1.0 # Standard deviation of noise\n",
    "LENGTH = 64 # Residue length to sample\n",
    "\n",
    "# Load Model\n",
    "# Note: Providing epoch=None loads the latest, which we set up.\n",
    "model = load_model(ROOT_DIR, MODEL_NAME, MODEL_VERSION).to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model {MODEL_NAME} loaded successfully.\")\n",
    "\n",
    "# Setup Output Directory\n",
    "out_dir = os.path.join('outputs', 'demo_samples')\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Sampling Loop\n",
    "print(f\"Sampling {BATCH_SIZE} structure(s) of length {LENGTH}...\")\n",
    "\n",
    "# Create mask: [Batch, MaxRes]\n",
    "# Model expects max_n_res sized mask usually, but checks sample loop\n",
    "max_n_res = model.config.io['max_n_res']\n",
    "mask = torch.cat([\n",
    "    torch.ones((BATCH_SIZE, LENGTH)),\n",
    "    torch.zeros((BATCH_SIZE, max_n_res - LENGTH))\n",
    "], dim=1).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # p_sample_loop returns a list of intermediate states. The last one is the final sample.\n",
    "    # [-1] fetches the last step\n",
    "    ts = model.p_sample_loop(mask, NOISE_SCALE, verbose=True)[-1]\n",
    "    \n",
    "    # Save samples\n",
    "    saved_files = []\n",
    "    for i in range(ts.shape[0]):\n",
    "        coords = ts[i].trans.detach().cpu().numpy()\n",
    "        coords = coords[:LENGTH] # Truncate to actual length\n",
    "        \n",
    "        filepath = os.path.join(out_dir, f'sample_{LENGTH}_{i}.npy')\n",
    "        np.savetxt(filepath, coords, fmt='%.3f', delimiter=',')\n",
    "        saved_files.append(filepath)\n",
    "        print(f\"Saved: {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8ae54d",
   "metadata": {},
   "source": [
    "## 5. 可视化 (Visualization)\n",
    "\n",
    "通过 Matplotlib 可视化生成的 C-alpha 骨架。\n",
    "\n",
    "Visualize the generated C-alpha backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3a03ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple visualizations using Matplotlib\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot_structure(filepath):\n",
    "    coords = np.loadtxt(filepath, delimiter=',')\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.set_proj_type('persp', focal_length=0.2)\n",
    "    \n",
    "    xs = coords[:, 0]\n",
    "    ys = coords[:, 1]\n",
    "    zs = coords[:, 2]\n",
    "    \n",
    "    # Draw backbone\n",
    "    ax.plot(xs, ys, zs, c='lightblue', linewidth=2, label='Backbone', alpha=0.8)\n",
    "    ax.scatter(xs, ys, zs, c=np.arange(len(xs)), cmap='viridis', s=50, depthshade=True)\n",
    "    \n",
    "    ax.set_xlabel('X (Å)')\n",
    "    ax.set_ylabel('Y (Å)')\n",
    "    ax.set_zlabel('Z (Å)')\n",
    "    ax.set_title(f'Structure: {os.path.basename(filepath)}')\n",
    "    \n",
    "    # View angle\n",
    "    ax.view_init(elev=20., azim=-35)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the first sample\n",
    "if saved_files:\n",
    "    plot_structure(saved_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d2c9ea",
   "metadata": {},
   "source": [
    "## 6. 评估与分析 (Evaluation & Analysis)\n",
    "\n",
    "本仓库提供工具来评估生成结构的创新性并分析其属性。\n",
    "The repository provides tools to evaluate the novelty of generated structures and analyze their properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9519c56",
   "metadata": {},
   "source": [
    "### 质量评估 (Quality Evaluation - scTM & pLDDT)\n",
    "\n",
    "在分析结果之前，我们需要评估生成骨架的质量（可设计性）。评估流程使用 ProteinMPNN 进行序列设计，使用 ESMFold 进行结构预测，从而计算自洽 TM-score (scTM) 和 pLDDT。\n",
    "Before analyzing the results, we need to evaluate the quality of the generated backbones (designability). The evaluation pipeline uses ProteinMPNN for sequence design and ESMFold for structure prediction to compute the self-consistency TM-score (scTM) and pLDDT.\n",
    "\n",
    "此步骤生成后续绘图所需的 `info.csv` 文件。\n",
    "This step generates the `info.csv` file needed for subsequent plots.\n",
    "\n",
    "**注意：** 此步骤需要 GPU，并且根据样本数量可能需要一些时间。\n",
    "**Note:** This step requires a GPU and may take some time depending on the number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7bcbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output directory for evaluations\n",
    "eval_output_dir = os.path.join(out_dir, 'evaluations')\n",
    "\n",
    "print(\"To run the Quality Evaluation pipeline (ProteinMPNN + ESMFold):\")\n",
    "print(f\"python evaluations/pipeline/evaluate.py --input_dir {out_dir} --output_dir {eval_output_dir}\")\n",
    "\n",
    "# Uncomment the following line to run it directly from the notebook (if environment allows)\n",
    "# !python evaluations/pipeline/evaluate.py --input_dir {out_dir} --output_dir {eval_output_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a6bc2b",
   "metadata": {},
   "source": [
    "### 创新性评估 (Novelty Evaluation)\n",
    "\n",
    "你可以通过使用 TM-score 将生成的蛋白质与参考数据库（如 PDB）进行比较，来评估其“创新性”。\n",
    "You can evaluate how \"novel\" your generated proteins are by comparing them against a reference database (e.g., PDB) using TM-score.\n",
    "\n",
    "提供了两个脚本：\n",
    "There are two provided scripts:\n",
    "1. `Novelty_Evaluation_CPU.py`: 穷举搜索（较慢，精确）。Exhaustive search (slower, exact).\n",
    "2. `Novelty_Evaluation_GPU.py`: 使用嵌入进行快速筛选的混合搜索（较快）。Hybrid search using embeddings for fast screening (faster).\n",
    "\n",
    "**使用示例 (生成命令):**\n",
    "下面的单元格生成你将在终端运行的命令。注意，你需要安装参考数据库（例如 `data/pdbstyle-2.08`）才能使其工作。\n",
    "The following cell generates the commands you would run in a terminal. Note that you need a reference database (e.g., `data/pdbstyle-2.08`) installed for these to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd2a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for evaluation\n",
    "eval_input_dir = eval_output_dir # Use the output from the previous step as input for analysis (it contains info.csv)\n",
    "ref_db_dir = os.path.join('data', 'pdbstyle-2.08')\n",
    "\n",
    "print(\"To run CPU-based Novelty Evaluation:\")\n",
    "print(f\"python evaluations/Novelty_Evaluation_CPU.py --input_dir {eval_input_dir} --ref_dir {ref_db_dir} --num_workers 4\")\n",
    "\n",
    "print(\"\\nTo run GPU-based Novelty Evaluation:\")\n",
    "print(f\"python evaluations/Novelty_Evaluation_GPU.py --input_dir {eval_input_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d3decb",
   "metadata": {},
   "source": [
    "### 分析绘图 (Analysis Plotting)\n",
    "\n",
    "一旦你有了评估结果（例如来自评估流程的 `info.csv` 或来自上述脚本的 `novelty.csv`），你就可以生成分析图表。\n",
    "Once you have evaluation results (e.g., `info.csv` from the evaluation pipeline or `novelty.csv` from the scripts above), you can generate analysis plots.\n",
    "\n",
    "1. **MDS 图 (MDS Plot)**: 可视化设计空间。Visualizes the design space.\n",
    "2. **综合分析 (General Analysis)**: 绘制 pLDDT 与 scTM 关系，SSE 分布等。Plots pLDDT vs scTM, SSE distribution, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c71b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"To plot Design Space MDS:\")\n",
    "print(f\"python evaluations/plot_genie_mds_novelty.py --input_dir {eval_input_dir} --output_file mds_plot.png\")\n",
    "\n",
    "print(\"\\nTo generate General Analysis Plots:\")\n",
    "print(f\"python evaluations/plot_genie_analysis.py --input_dir {eval_input_dir} --output_file analysis_plot.png\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
