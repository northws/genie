{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d9ddc24",
   "metadata": {},
   "source": [
    "# Genie: De Novo Protein Design Demo\n",
    "\n",
    "This notebook demonstrates how to use the Genie model for de novo protein backbone generation.\n",
    "\n",
    "## 1. Environment Setup\n",
    "\n",
    "First, we import necessary libraries and check for GPU availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d4a83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import shutil\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Add current directory to path\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from genie.config import Config\n",
    "from genie.utils.model_io import load_model\n",
    "\n",
    "# Check GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3654824b",
   "metadata": {},
   "source": [
    "## 2. Prepare Pre-trained Weights\n",
    "\n",
    "The provided weights are in a flat structure. The sampling script expects a specific directory hierarchy (`runs/<model_name>/version_<X>/checkpoints/`). We will create a temporary `runs` directory and link the weights correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80adcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_weights(source_path, model_name, target_root='runs', version=0):\n",
    "    \"\"\"\n",
    "    Restructures weights from source_path to target_root compatible with Genie's loader.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Target paths\n",
    "    run_dir = os.path.join(target_root, model_name)\n",
    "    version_dir = os.path.join(run_dir, f'version_{version}')\n",
    "    ckpt_dir = os.path.join(version_dir, 'checkpoints')\n",
    "    \n",
    "    # Create directories\n",
    "    os.makedirs(ckpt_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Copy/Link Configuration\n",
    "    src_config = os.path.join(source_path, 'configuration')\n",
    "    dst_config = os.path.join(run_dir, 'configuration')\n",
    "    if os.path.exists(src_config) and not os.path.exists(dst_config):\n",
    "        shutil.copy(src_config, dst_config)\n",
    "        print(f\"Copied configuration to {dst_config}\")\n",
    "        \n",
    "    # 2. Link Checkpoint\n",
    "    # Find .ckpt file in source\n",
    "    ckpts = glob.glob(os.path.join(source_path, '*.ckpt'))\n",
    "    if not ckpts:\n",
    "        raise FileNotFoundError(f\"No .ckpt files found in {source_path}\")\n",
    "    \n",
    "    src_ckpt = ckpts[0] # Take the first one found\n",
    "    ckpt_name = os.path.basename(src_ckpt)\n",
    "    dst_ckpt = os.path.join(ckpt_dir, ckpt_name)\n",
    "    \n",
    "    if not os.path.exists(dst_ckpt):\n",
    "        # Use symlink if possible, else copy\n",
    "        try:\n",
    "            os.symlink(os.path.abspath(src_ckpt), dst_ckpt)\n",
    "            print(f\"Symlinked checkpoint to {dst_ckpt}\")\n",
    "        except OSError:\n",
    "            shutil.copy(src_ckpt, dst_ckpt)\n",
    "            print(f\"Copied checkpoint to {dst_ckpt}\")\n",
    "\n",
    "# Define model to use\n",
    "MODEL_NAME = 'scope_l_128'\n",
    "WEIGHTS_PATH = os.path.join('weights', MODEL_NAME)\n",
    "\n",
    "# Set up the folder structure\n",
    "setup_weights(WEIGHTS_PATH, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819d6375",
   "metadata": {},
   "source": [
    "## 3. Sampling\n",
    "\n",
    "Now we load the model and generate some protein backbone structures.\n",
    "We will generate proteins of length 64 as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c1108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for sampling\n",
    "MODEL_VERSION = 0 # As set up above\n",
    "ROOT_DIR = 'runs'\n",
    "BATCH_SIZE = 1 # Number of samples per batch\n",
    "NOISE_SCALE = 1.0 # Standard deviation of noise\n",
    "LENGTH = 64 # Residue length to sample\n",
    "\n",
    "# Load Model\n",
    "# Note: Providing epoch=None loads the latest, which we set up.\n",
    "model = load_model(ROOT_DIR, MODEL_NAME, MODEL_VERSION).to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model {MODEL_NAME} loaded successfully.\")\n",
    "\n",
    "# Setup Output Directory\n",
    "out_dir = os.path.join('outputs', 'demo_samples')\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Sampling Loop\n",
    "print(f\"Sampling {BATCH_SIZE} structure(s) of length {LENGTH}...\")\n",
    "\n",
    "# Create mask: [Batch, MaxRes]\n",
    "# Model expects max_n_res sized mask usually, but checks sample loop\n",
    "max_n_res = model.config.io['max_n_res']\n",
    "mask = torch.cat([\n",
    "    torch.ones((BATCH_SIZE, LENGTH)),\n",
    "    torch.zeros((BATCH_SIZE, max_n_res - LENGTH))\n",
    "], dim=1).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # p_sample_loop returns a list of intermediate states. The last one is the final sample.\n",
    "    # [-1] fetches the last step\n",
    "    ts = model.p_sample_loop(mask, NOISE_SCALE, verbose=True)[-1]\n",
    "    \n",
    "    # Save samples\n",
    "    saved_files = []\n",
    "    for i in range(ts.shape[0]):\n",
    "        coords = ts[i].trans.detach().cpu().numpy()\n",
    "        coords = coords[:LENGTH] # Truncate to actual length\n",
    "        \n",
    "        filepath = os.path.join(out_dir, f'sample_{LENGTH}_{i}.npy')\n",
    "        np.savetxt(filepath, coords, fmt='%.3f', delimiter=',')\n",
    "        saved_files.append(filepath)\n",
    "        print(f\"Saved: {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8ae54d",
   "metadata": {},
   "source": [
    "## 4. Visualization\n",
    "\n",
    "Visualize the generated C-alpha backbone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3a03ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple visualizations using Matplotlib\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def plot_structure(filepath):\n",
    "    coords = np.loadtxt(filepath, delimiter=',')\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.set_proj_type('persp', focal_length=0.2)\n",
    "    \n",
    "    xs = coords[:, 0]\n",
    "    ys = coords[:, 1]\n",
    "    zs = coords[:, 2]\n",
    "    \n",
    "    # Draw backbone\n",
    "    ax.plot(xs, ys, zs, c='lightblue', linewidth=2, label='Backbone', alpha=0.8)\n",
    "    ax.scatter(xs, ys, zs, c=np.arange(len(xs)), cmap='viridis', s=50, depthshade=True)\n",
    "    \n",
    "    ax.set_xlabel('X (Å)')\n",
    "    ax.set_ylabel('Y (Å)')\n",
    "    ax.set_zlabel('Z (Å)')\n",
    "    ax.set_title(f'Structure: {os.path.basename(filepath)}')\n",
    "    \n",
    "    # View angle\n",
    "    ax.view_init(elev=20., azim=-35)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the first sample\n",
    "if saved_files:\n",
    "    plot_structure(saved_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d2c9ea",
   "metadata": {},
   "source": [
    "## 5. Evaluation & Analysis\n",
    "\n",
    "The repository provides tools to evaluate the novelty of generated structures and analyze their properties.\n",
    "\n",
    "### Novelty Evaluation\n",
    "You can evaluate how \"novel\" your generated proteins are by comparing them against a reference database (e.g., PDB) using TM-score.\n",
    "\n",
    "There are two provided scripts:\n",
    "1. `Novelty_Evaluation_CPU.py`: Exhaustive search (slower, exact).\n",
    "2. `Novelty_Evaluation_GPU.py`: Hybrid search using embeddings for fast screening (faster).\n",
    "\n",
    "**Example Usage (Command generation):**\n",
    "The following cell generates the commands you would run in a terminal. Note that you need a reference database (e.g., `data/pdbstyle-2.08`) installed for these to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd2a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for evaluation\n",
    "eval_input_dir = out_dir # The directory where we saved samples\n",
    "ref_db_dir = os.path.join('data', 'pdbstyle-2.08')\n",
    "\n",
    "print(\"To run CPU-based Novelty Evaluation:\")\n",
    "print(f\"python Novelty_Evaluation_CPU.py --input_dir {eval_input_dir} --ref_dir {ref_db_dir} --num_workers 4\")\n",
    "\n",
    "print(\"\\nTo run GPU-based Novelty Evaluation:\")\n",
    "print(f\"python Novelty_Evaluation_GPU.py --input_dir {eval_input_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d3decb",
   "metadata": {},
   "source": [
    "### Analysis Plotting\n",
    "\n",
    "Once you have evaluation results (e.g., `info.csv` from the evaluation pipeline or `novelty.csv` from the scripts above), you can generate analysis plots.\n",
    "\n",
    "1. **MDS Plot**: Visualizes the design space.\n",
    "2. **General Analysis**: Plots pLDDT vs scTM, SSE distribution, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c71b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"To plot Design Space MDS:\")\n",
    "print(f\"python plot_genie_mds_novelty.py --input_dir {eval_input_dir} --output_file mds_plot.png\")\n",
    "\n",
    "print(\"\\nTo generate General Analysis Plots:\")\n",
    "print(f\"python plot_genie_analysis.py --input_dir {eval_input_dir} --output_file analysis_plot.png\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
